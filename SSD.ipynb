{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "469d06fa-b099-43a7-bb62-92c466771d4b",
   "metadata": {},
   "source": [
    "# Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a705a320-2ddd-4a10-aba9-5ceb8c012b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%matplolib` not found.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplolib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640efa42-0a91-4c66-81ff-19637bb2c06b",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95a8494b-37cb-46d1-ac43-d03de123779c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_images = \"intersection.jpeg, traffic.jpeg, jungle.jpeg, walkingdog.jpeg, us.jpeg, my_street.jpeg\".split(\", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663b5c33-d317-4088-b9ef-38e29fec7561",
   "metadata": {},
   "source": [
    "# get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97fe38a9-314c-4dfe-ad41-e03d160a57f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 14:06:28.214605: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# getting the model from\n",
    "# https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md\n",
    "\n",
    "url = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz'\n",
    "\n",
    "PATH_TO_MODEL_DIR = tf.keras.utils.get_file(\n",
    "    fname='ssd_resnet101_v1_fpn_640x640_coco17_tpu-8',\n",
    "    origin=url,\n",
    "    untar=True)\n",
    "\n",
    "PATH_TO_SAVED_MODEL = PATH_TO_MODEL_DIR + \"/saved_model\"\n",
    "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
    "\n",
    "# download labels\n",
    "url = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/data/mscoco_label_map.pbtxt'\n",
    "\n",
    "PATH_TO_LABELS = tf.keras.utils.get_file(\n",
    "    fname='mscoco_label_map.pbtxt',\n",
    "    origin=url,\n",
    "    untar=False)\n",
    "\n",
    "category_index = label_map_util.create_category_index_from_labelmap(\n",
    "    PATH_TO_LABELS,\n",
    "    use_display_name=True)\n",
    "\n",
    "# optionaly you can pring existing categories\n",
    "#print(\"Here is a list of existing categories:\", category_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb287e2-6f13-45b9-8678-abe8630bee30",
   "metadata": {},
   "source": [
    "# detectionFucntion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39f71b48-cd9b-448d-afac-b354bf35f780",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Python inputs incompatible with input_signature:\n  inputs: (\n    tf.Tensor(\n[[[[153 150 151 255]\n   [163 160 161 255]\n   [159 156 157 255]\n   ...\n   [196 189 194 255]\n   [196 189 196 255]\n   [196 189 196 255]]\n\n  [[155 152 153 255]\n   [163 160 161 255]\n   [157 154 155 255]\n   ...\n   [196 189 195 255]\n   [197 190 197 255]\n   [196 188 196 255]]\n\n  [[149 146 147 255]\n   [154 151 152 255]\n   [150 147 147 255]\n   ...\n   [194 187 194 255]\n   [196 189 196 255]\n   [195 188 195 255]]\n\n  ...\n\n  [[155 148 150 255]\n   [150 144 146 255]\n   [142 138 139 255]\n   ...\n   [ 91  95 102 255]\n   [ 94  98 105 255]\n   [ 88  92  99 255]]\n\n  [[153 150 152 255]\n   [144 141 142 255]\n   [153 152 153 255]\n   ...\n   [ 97 100 107 255]\n   [ 93  97 104 255]\n   [ 96  99 106 255]]\n\n  [[142 143 145 255]\n   [143 143 145 255]\n   [151 151 153 255]\n   ...\n   [ 90  94 101 255]\n   [ 89  93  99 255]\n   [ 89  93 100 255]]]], shape=(1, 779, 1040, 4), dtype=uint8))\n  input_signature: (\n    TensorSpec(shape=(1, None, None, 3), dtype=tf.uint8, name=None)).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdetect_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmy_street.jpeg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mdetect_objects\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      5\u001b[0m img_to_tensor \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(img_to_np)\n\u001b[1;32m      7\u001b[0m input_tensor \u001b[38;5;241m=\u001b[39m img_to_tensor[tf\u001b[38;5;241m.\u001b[39mnewaxis, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n\u001b[0;32m----> 9\u001b[0m detections \u001b[38;5;241m=\u001b[39m \u001b[43mdetect_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m num_detections \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(detections\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_detections\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     12\u001b[0m detections \u001b[38;5;241m=\u001b[39m {key: value[\u001b[38;5;241m0\u001b[39m, :num_detections]\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     13\u001b[0m                \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m detections\u001b[38;5;241m.\u001b[39mitems()}\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gig/lib/python3.10/site-packages/tensorflow/python/saved_model/load.py:704\u001b[0m, in \u001b[0;36m_call_attribute\u001b[0;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_attribute\u001b[39m(instance, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 704\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minstance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gig/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gig/lib/python3.10/site-packages/tensorflow/python/eager/function_spec.py:531\u001b[0m, in \u001b[0;36m_convert_inputs_to_signature\u001b[0;34m(inputs, input_signature, flat_input_signature)\u001b[0m\n\u001b[1;32m    523\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen input_signature is provided, all inputs to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    524\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe Python function must be convertible to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    525\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensors:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    526\u001b[0m                        \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mformat_error_message(inputs,\u001b[38;5;250m \u001b[39minput_signature)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mis_compatible_with(other) \u001b[38;5;28;01mfor\u001b[39;00m spec, other \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[1;32m    529\u001b[0m     flat_input_signature,\n\u001b[1;32m    530\u001b[0m     flatten_inputs)):\n\u001b[0;32m--> 531\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPython inputs incompatible with input_signature:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    532\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mformat_error_message(inputs,\u001b[38;5;250m \u001b[39minput_signature)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m need_packing:\n\u001b[1;32m    535\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mpack_sequence_as(\n\u001b[1;32m    536\u001b[0m       structure\u001b[38;5;241m=\u001b[39minput_signature,\n\u001b[1;32m    537\u001b[0m       flat_sequence\u001b[38;5;241m=\u001b[39mflatten_inputs,\n\u001b[1;32m    538\u001b[0m       expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: Python inputs incompatible with input_signature:\n  inputs: (\n    tf.Tensor(\n[[[[153 150 151 255]\n   [163 160 161 255]\n   [159 156 157 255]\n   ...\n   [196 189 194 255]\n   [196 189 196 255]\n   [196 189 196 255]]\n\n  [[155 152 153 255]\n   [163 160 161 255]\n   [157 154 155 255]\n   ...\n   [196 189 195 255]\n   [197 190 197 255]\n   [196 188 196 255]]\n\n  [[149 146 147 255]\n   [154 151 152 255]\n   [150 147 147 255]\n   ...\n   [194 187 194 255]\n   [196 189 196 255]\n   [195 188 195 255]]\n\n  ...\n\n  [[155 148 150 255]\n   [150 144 146 255]\n   [142 138 139 255]\n   ...\n   [ 91  95 102 255]\n   [ 94  98 105 255]\n   [ 88  92  99 255]]\n\n  [[153 150 152 255]\n   [144 141 142 255]\n   [153 152 153 255]\n   ...\n   [ 97 100 107 255]\n   [ 93  97 104 255]\n   [ 96  99 106 255]]\n\n  [[142 143 145 255]\n   [143 143 145 255]\n   [151 151 153 255]\n   ...\n   [ 90  94 101 255]\n   [ 89  93  99 255]\n   [ 89  93 100 255]]]], shape=(1, 779, 1040, 4), dtype=uint8))\n  input_signature: (\n    TensorSpec(shape=(1, None, None, 3), dtype=tf.uint8, name=None))."
     ]
    }
   ],
   "source": [
    "detect_objects(\"my_street.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bea92ddb-08ee-4725-a028-75352a1ca687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(img):\n",
    "    \n",
    "    img_dir = \"./original_img/\"\n",
    "    img_to_np = np.array(Image.open(img_dir + img))\n",
    "    img_to_tensor = tf.convert_to_tensor(img_to_np)\n",
    "    \n",
    "    input_tensor = img_to_tensor[tf.newaxis, ...]\n",
    "    \n",
    "    detections = detect_fn(input_tensor)\n",
    "    \n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                   for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    image_np_with_detections = img_to_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "          image_np_with_detections,\n",
    "          detections['detection_boxes'],\n",
    "          detections['detection_classes'],\n",
    "          detections['detection_scores'],\n",
    "          category_index,\n",
    "          use_normalized_coordinates=True,\n",
    "          max_boxes_to_draw=200,\n",
    "          min_score_thresh=.30,\n",
    "          agnostic_mode=False)\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.imshow(image_np_with_detections)\n",
    "    print(img)\n",
    "    plt.savefig(f\"detected_{img}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c6a18c-bae5-4a02-9c36-2a4753d60baf",
   "metadata": {},
   "source": [
    "# detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d99be275-2214-46df-8735-1e1a21e39107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intersection.jpeg\n",
      "traffic.jpeg\n"
     ]
    }
   ],
   "source": [
    "for img in list_of_images:\n",
    "    detect_objects(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd0b8ec-83c9-493e-8b27-f3bda5b9d1b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gig",
   "language": "python",
   "name": "gig"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
