{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "469d06fa-b099-43a7-bb62-92c466771d4b",
   "metadata": {},
   "source": [
    "# Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a705a320-2ddd-4a10-aba9-5ceb8c012b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%matplolib` not found.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplolib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640efa42-0a91-4c66-81ff-19637bb2c06b",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95a8494b-37cb-46d1-ac43-d03de123779c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_images = \"intersection.jpeg, traffic.jpeg, jungle.jpeg, walkingdog.jpeg, us.jpeg, my_street.jpeg\".split(\", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663b5c33-d317-4088-b9ef-38e29fec7561",
   "metadata": {},
   "source": [
    "# get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97fe38a9-314c-4dfe-ad41-e03d160a57f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 14:06:28.214605: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# getting the model from\n",
    "# https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md\n",
    "\n",
    "url = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz'\n",
    "\n",
    "PATH_TO_MODEL_DIR = tf.keras.utils.get_file(\n",
    "    fname='ssd_resnet101_v1_fpn_640x640_coco17_tpu-8',\n",
    "    origin=url,\n",
    "    untar=True)\n",
    "\n",
    "PATH_TO_SAVED_MODEL = PATH_TO_MODEL_DIR + \"/saved_model\"\n",
    "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
    "\n",
    "# download labels\n",
    "url = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/data/mscoco_label_map.pbtxt'\n",
    "\n",
    "PATH_TO_LABELS = tf.keras.utils.get_file(\n",
    "    fname='mscoco_label_map.pbtxt',\n",
    "    origin=url,\n",
    "    untar=False)\n",
    "\n",
    "category_index = label_map_util.create_category_index_from_labelmap(\n",
    "    PATH_TO_LABELS,\n",
    "    use_display_name=True)\n",
    "\n",
    "# optionaly you can pring existing categories\n",
    "#print(\"Here is a list of existing categories:\", category_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb287e2-6f13-45b9-8678-abe8630bee30",
   "metadata": {},
   "source": [
    "# detectionFucntion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5ab59c6d-1a02-420d-a3e9-397d8cf9194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(img, list_of_desired_obj = None):\n",
    "\n",
    "    \"\"\"\n",
    "    arguments:\n",
    "        img - image name\n",
    "        list_of_desired_obj - list of desired object\n",
    "                                if not specifeid then all detected objects are shown\n",
    "    return:\n",
    "        save an image with detected objects\n",
    "        \n",
    "    description:\n",
    "        I block\n",
    "            given image (img) is read by i.Image.open, ii.tranformed to tensor, iii.reshaped to have batch\n",
    "        II block\n",
    "            detect all objects using detect_fn funciton\n",
    "        III reshape to remove batch dimention, select object of interest if needed\n",
    "        IV add frames around detected object\n",
    "        V create an image with frames\n",
    "    \"\"\"\n",
    "    img_dir = \"./original_img/\"\n",
    "    img_to_np = np.array(Image.open(img_dir + \"my_street.jpeg\"))\n",
    "    img_to_tensor = tf.convert_to_tensor(img_to_np)\n",
    "    input_tensor = img_to_tensor[tf.newaxis, ...]\n",
    "    \n",
    "    detections = detect_fn(input_tensor)\n",
    "    \n",
    "    num_detections = int(detections.pop(\"num_detections\"))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                   for key, value in detections.items()}\n",
    "    detections[\"detection_classes\"] = detections[\"detection_classes\"].astype(np.int64)\n",
    "    if list_of_desired_obj:\n",
    "        obj_list = list_of_desired_obj\n",
    "        requested_obj = {}\n",
    "        for key in detections.keys():\n",
    "            requested_obj[key] = np.array([i for i,j in zip(detections[key],\n",
    "                                                            detections[\"detection_classes\"])\n",
    "                                           if j in obj_list])\n",
    "        requested_obj[\"num_detections\"] = num_detections\n",
    "        detections = requested_obj\n",
    "    detections[\"num_detections\"] = num_detections\n",
    "    \n",
    "    image_np_with_detections = img_to_np.copy()\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "          image_np_with_detections,\n",
    "          detections[\"detection_boxes\"],\n",
    "          detections[\"detection_classes\"],\n",
    "          detections[\"detection_scores\"],\n",
    "          category_index,\n",
    "          use_normalized_coordinates=True,\n",
    "          max_boxes_to_draw=200,\n",
    "          min_score_thresh=.30,\n",
    "          agnostic_mode=False)\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.imshow(image_np_with_detections)\n",
    "    plt.savefig(f\"detected_{img}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c6a18c-bae5-4a02-9c36-2a4753d60baf",
   "metadata": {},
   "source": [
    "# detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d99be275-2214-46df-8735-1e1a21e39107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intersection.jpeg\n",
      "traffic.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yt/vsz4v53j4bv674jbw4t304p80000gn/T/ipykernel_74975/3589691641.py:34: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  plt.figure(figsize=(15, 10))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jungle.jpeg\n",
      "walkingdog.jpeg\n",
      "us.jpeg\n",
      "my_street.jpeg\n"
     ]
    }
   ],
   "source": [
    "for img in list_of_images:\n",
    "    detect_objects(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gig",
   "language": "python",
   "name": "gig"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
